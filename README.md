# ğŸš€ Projeto N8N via Docker

Este projeto permite rodar o [N8N](https://n8n.io/) localmente utilizando Docker, com persistÃªncia de dados, autenticaÃ§Ã£o bÃ¡sica, integraÃ§Ã£o com banco de dados Postgres, Redis para filas e o Ollama para IA generativa.

---

## ğŸ“¦ ServiÃ§os inclusos

- **Postgres**: Banco de dados para persistÃªncia dos workflows e credenciais.
- **Redis**: Gerenciamento de filas para execuÃ§Ã£o dos workflows.
- **Ollama**: API para rodar modelos de IA localmente.
- **N8N**: Plataforma de automaÃ§Ã£o de workflows.

---

## âš™ï¸ Como levantar o ambiente

1. **Clone o repositÃ³rio e acesse a pasta:**
   ```sh
   git clone <url-do-repo>
   cd N8N
   ```

2. **Suba os containers:**
   ```sh
   docker compose up -d
   ```

---

## ğŸ—„ï¸ PersistÃªncia de dados

- Os dados do N8N (workflows e credenciais) ficam em `/home/node/.n8n` dentro do container.
- O volume `n8n_data` garante que os dados sejam persistidos mesmo apÃ³s reiniciar os containers.
- Outros volumes:
  - `postgres_data`: dados do Postgres
  - `redis_data`: dados do Redis
  - `ollama_data`: modelos baixados do Ollama

---

## ğŸ”’ AutenticaÃ§Ã£o

- O N8N estÃ¡ protegido por autenticaÃ§Ã£o bÃ¡sica:
  - **UsuÃ¡rio:** `admin`
  - **Senha:** `senha-super-segura`
- O timezone estÃ¡ configurado para `America/Sao_Paulo`.

---

## ğŸŒ Acessando o N8N

Abra o navegador em:

ğŸ‘‰ [http://localhost:5678](http://localhost:5678)

---

## ğŸ¤– Testando o Ollama

### 1ï¸âƒ£ Listar modelos disponÃ­veis

Dentro do container Ollama, rode:

```sh
docker exec -it <nome_do_container_ollama> ollama list
```

### 2ï¸âƒ£ Baixar o modelo desejado

Exemplo para baixar o modelo `llama3`:

```sh
docker exec -it <nome_do_container_ollama> ollama pull llama3
```

VocÃª pode baixar outros modelos, como `mistral`, `codellama`, etc.

### 3ï¸âƒ£ Testar o modelo

ApÃ³s baixar, teste com o comando:

```sh
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3",
    "prompt": "Explique o que Ã© n8n em 3 frases curtas."
  }'
```

Se tudo estiver certo, o modelo irÃ¡ retornar uma resposta. âœ…

---

## ğŸ“ ObservaÃ§Ãµes

- O serviÃ§o N8N depende do Postgres, Redis e Ollama, garantindo que todos estejam prontos antes de iniciar.
- Os workflows podem ser salvos na pasta `./workflows` do projeto, que Ã© montada no container.

---

## ğŸ“š ReferÃªncias

- [DocumentaÃ§Ã£o oficial do N8N](https://docs.n8n.io/)
- [DocumentaÃ§Ã£o do Ollama](https://ollama.com/)